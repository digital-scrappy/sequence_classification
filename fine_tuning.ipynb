{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c325a273-789f-4b99-a1cc-7fe55b61fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from strip_headers import strip_headers\n",
    "import re\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f78d946e-13f0-42b7-b012-eacc6e698882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GutenbergDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a57df15-f360-4a43-8d37-d43a10cb4273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_people(people, text):\n",
    "    new_text = text\n",
    "    for person in people:\n",
    "        new_text = re.sub(person, 'Person', new_text, flags=re.IGNORECASE)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33608e06-69ee-41a0-b548-be817413a19a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-german-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "data_dir = Path.cwd() / \"data\"\n",
    "metadata = pl.read_csv(data_dir / \"metadata.csv\")\n",
    "\n",
    "\n",
    "\n",
    "authors = [\"Goethe, Johann Wolfgang von\", \"Schiller, Friedrich\"]\n",
    "author_mapping = {\"Goethe, Johann Wolfgang von\": 0,\n",
    "                  \"Schiller, Friedrich\": 1}\n",
    "\n",
    "metadata = metadata.filter(pl.col(\"language\") == \"['de']\")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-german-cased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-german-cased\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40c8d012-1e0b-4168-b804-2ef28dfec509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"people.txt\", \"r\") as f:\n",
    "    #removing \\n \n",
    "    people = [person[:-1] for person in f.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0806506-47ba-48a3-93d3-d8e3a8db9540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       ".pl-dataframe > thead > tr > th {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<table border=\"1\" class=\"dataframe pl-dataframe\">\n",
       "<small>shape: (10, 9)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "id\n",
       "</th>\n",
       "<th>\n",
       "title\n",
       "</th>\n",
       "<th>\n",
       "author\n",
       "</th>\n",
       "<th>\n",
       "authoryearofbirth\n",
       "</th>\n",
       "<th>\n",
       "authoryearofdeath\n",
       "</th>\n",
       "<th>\n",
       "language\n",
       "</th>\n",
       "<th>\n",
       "downloads\n",
       "</th>\n",
       "<th>\n",
       "subjects\n",
       "</th>\n",
       "<th>\n",
       "type\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG47804&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Die Räuber: Ei...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Schiller, Frie...\n",
       "</td>\n",
       "<td>\n",
       "1759\n",
       "</td>\n",
       "<td>\n",
       "1805\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "364\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Tragedies&#x27;, ...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG6383&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Die Jungfrau v...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Schiller, Frie...\n",
       "</td>\n",
       "<td>\n",
       "1759\n",
       "</td>\n",
       "<td>\n",
       "1805\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "36\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Tragedies&#x27;, ...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG6496&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Die Braut von ...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Schiller, Frie...\n",
       "</td>\n",
       "<td>\n",
       "1759\n",
       "</td>\n",
       "<td>\n",
       "1805\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "28\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Sicily (Ital...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG6498&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Kabale und Lie...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Schiller, Frie...\n",
       "</td>\n",
       "<td>\n",
       "1759\n",
       "</td>\n",
       "<td>\n",
       "1805\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "66\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Love -- Dram...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG6499&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Die Verschwöru...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Schiller, Frie...\n",
       "</td>\n",
       "<td>\n",
       "1759\n",
       "</td>\n",
       "<td>\n",
       "1805\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "14\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Fiéschi, Gia...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG6505&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Turandot, Prin...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Schiller, Frie...\n",
       "</td>\n",
       "<td>\n",
       "1759\n",
       "</td>\n",
       "<td>\n",
       "1805\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "23\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;China -- Dra...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG6518&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Wallensteins L...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Schiller, Frie...\n",
       "</td>\n",
       "<td>\n",
       "1759\n",
       "</td>\n",
       "<td>\n",
       "1805\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "137\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Wallenstein,...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG6525&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Die Piccolomin...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Schiller, Frie...\n",
       "</td>\n",
       "<td>\n",
       "1759\n",
       "</td>\n",
       "<td>\n",
       "1805\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "41\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&quot;Thirty Years...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG6549&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Wallensteins T...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Schiller, Frie...\n",
       "</td>\n",
       "<td>\n",
       "1759\n",
       "</td>\n",
       "<td>\n",
       "1805\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "40\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Wallenstein,...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG7939&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Die Huldigung ...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Schiller, Frie...\n",
       "</td>\n",
       "<td>\n",
       "1759\n",
       "</td>\n",
       "<td>\n",
       "1805\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "6\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;German poetr...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (10, 9)\n",
       "┌─────────┬─────────────┬────────────┬────────────┬─────┬──────────┬───────────┬────────────┬──────┐\n",
       "│ id      ┆ title       ┆ author     ┆ authoryear ┆ ... ┆ language ┆ downloads ┆ subjects   ┆ type │\n",
       "│ ---     ┆ ---         ┆ ---        ┆ ofbirth    ┆     ┆ ---      ┆ ---       ┆ ---        ┆ ---  │\n",
       "│ str     ┆ str         ┆ str        ┆ ---        ┆     ┆ str      ┆ i64       ┆ str        ┆ str  │\n",
       "│         ┆             ┆            ┆ i64        ┆     ┆          ┆           ┆            ┆      │\n",
       "╞═════════╪═════════════╪════════════╪════════════╪═════╪══════════╪═══════════╪════════════╪══════╡\n",
       "│ PG47804 ┆ Die Räuber: ┆ Schiller,  ┆ 1759       ┆ ... ┆ ['de']   ┆ 364       ┆ {'Tragedie ┆ null │\n",
       "│         ┆ Ein         ┆ Friedrich  ┆            ┆     ┆          ┆           ┆ s',        ┆      │\n",
       "│         ┆ Schauspiel  ┆            ┆            ┆     ┆          ┆           ┆ 'German    ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ drama',    ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ 'B...      ┆      │\n",
       "│ PG6383  ┆ Die         ┆ Schiller,  ┆ 1759       ┆ ... ┆ ['de']   ┆ 36        ┆ {'Tragedie ┆ null │\n",
       "│         ┆ Jungfrau    ┆ Friedrich  ┆            ┆     ┆          ┆           ┆ s',        ┆      │\n",
       "│         ┆ von Orleans ┆            ┆            ┆     ┆          ┆           ┆ 'France -- ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ History... ┆      │\n",
       "│ PG6496  ┆ Die Braut   ┆ Schiller,  ┆ 1759       ┆ ... ┆ ['de']   ┆ 28        ┆ {'Sicily   ┆ null │\n",
       "│         ┆ von Messina ┆ Friedrich  ┆            ┆     ┆          ┆           ┆ (Italy) -- ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ Drama'}    ┆      │\n",
       "│ PG6498  ┆ Kabale und  ┆ Schiller,  ┆ 1759       ┆ ... ┆ ['de']   ┆ 66        ┆ {'Love --  ┆ null │\n",
       "│         ┆ Liebe: Ein  ┆ Friedrich  ┆            ┆     ┆          ┆           ┆ Drama'}    ┆      │\n",
       "│         ┆ bürgerlich. ┆            ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│         ┆ ..          ┆            ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│ ...     ┆ ...         ┆ ...        ┆ ...        ┆ ... ┆ ...      ┆ ...       ┆ ...        ┆ ...  │\n",
       "│ PG6518  ┆ Wallenstein ┆ Schiller,  ┆ 1759       ┆ ... ┆ ['de']   ┆ 137       ┆ {'Wallenst ┆ null │\n",
       "│         ┆ s Lager     ┆ Friedrich  ┆            ┆     ┆          ┆           ┆ ein,       ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ Albrecht   ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ Wenzel     ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ E...       ┆      │\n",
       "│ PG6525  ┆ Die         ┆ Schiller,  ┆ 1759       ┆ ... ┆ ['de']   ┆ 41        ┆ {\"Thirty   ┆ null │\n",
       "│         ┆ Piccolomini ┆ Friedrich  ┆            ┆     ┆          ┆           ┆ Years'     ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ War,       ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ 1618-1648  ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ -...       ┆      │\n",
       "│ PG6549  ┆ Wallenstein ┆ Schiller,  ┆ 1759       ┆ ... ┆ ['de']   ┆ 40        ┆ {'Wallenst ┆ null │\n",
       "│         ┆ s Tod       ┆ Friedrich  ┆            ┆     ┆          ┆           ┆ ein,       ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ Albrecht   ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ Wenzel     ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ E...       ┆      │\n",
       "│ PG7939  ┆ Die         ┆ Schiller,  ┆ 1759       ┆ ... ┆ ['de']   ┆ 6         ┆ {'German   ┆ null │\n",
       "│         ┆ Huldigung   ┆ Friedrich  ┆            ┆     ┆          ┆           ┆ poetry --  ┆      │\n",
       "│         ┆ der Künste  ┆            ┆            ┆     ┆          ┆           ┆ 18th centu ┆      │\n",
       "│         ┆             ┆            ┆            ┆     ┆          ┆           ┆ ry'...     ┆      │\n",
       "└─────────┴─────────────┴────────────┴────────────┴─────┴──────────┴───────────┴────────────┴──────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.filter((pl.col(\"author\") == \"Schiller, Friedrich\") & (pl.col(\"subjects\").str.contains(\"Drama\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e85b9eb-0378-4569-bda6-c8464d4becb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       ".pl-dataframe > thead > tr > th {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<table border=\"1\" class=\"dataframe pl-dataframe\">\n",
       "<small>shape: (12, 9)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "id\n",
       "</th>\n",
       "<th>\n",
       "title\n",
       "</th>\n",
       "<th>\n",
       "author\n",
       "</th>\n",
       "<th>\n",
       "authoryearofbirth\n",
       "</th>\n",
       "<th>\n",
       "authoryearofdeath\n",
       "</th>\n",
       "<th>\n",
       "language\n",
       "</th>\n",
       "<th>\n",
       "downloads\n",
       "</th>\n",
       "<th>\n",
       "subjects\n",
       "</th>\n",
       "<th>\n",
       "type\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG10353&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Satyros oder D...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Goethe, Johann...\n",
       "</td>\n",
       "<td>\n",
       "1749\n",
       "</td>\n",
       "<td>\n",
       "1832\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "2\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Drama&#x27;}&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG10425&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Torquato Tasso...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Goethe, Johann...\n",
       "</td>\n",
       "<td>\n",
       "1749\n",
       "</td>\n",
       "<td>\n",
       "1832\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "41\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Tasso, Torqu...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG10426&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Die natürliche...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Goethe, Johann...\n",
       "</td>\n",
       "<td>\n",
       "1749\n",
       "</td>\n",
       "<td>\n",
       "1832\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "8\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Drama&#x27;}&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG10428&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Die Aufgeregte...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Goethe, Johann...\n",
       "</td>\n",
       "<td>\n",
       "1749\n",
       "</td>\n",
       "<td>\n",
       "1832\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "6\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Europe -- So...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG2054&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Iphigenie auf ...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Goethe, Johann...\n",
       "</td>\n",
       "<td>\n",
       "1749\n",
       "</td>\n",
       "<td>\n",
       "1832\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "104\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Iphigenia (M...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG21000&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Faust: Eine Tr...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Goethe, Johann...\n",
       "</td>\n",
       "<td>\n",
       "1749\n",
       "</td>\n",
       "<td>\n",
       "1832\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "959\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Legends -- G...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG2146&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Egmont&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Goethe, Johann...\n",
       "</td>\n",
       "<td>\n",
       "1749\n",
       "</td>\n",
       "<td>\n",
       "1832\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "42\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Tragedies&#x27;, ...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG2229&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Faust: Der Tra...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Goethe, Johann...\n",
       "</td>\n",
       "<td>\n",
       "1749\n",
       "</td>\n",
       "<td>\n",
       "1832\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "670\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Legends -- G...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG2230&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Faust: Der Tra...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Goethe, Johann...\n",
       "</td>\n",
       "<td>\n",
       "1749\n",
       "</td>\n",
       "<td>\n",
       "1832\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "279\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Legends -- G...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG2321&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Götz von Berli...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Goethe, Johann...\n",
       "</td>\n",
       "<td>\n",
       "1749\n",
       "</td>\n",
       "<td>\n",
       "1832\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "26\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Berlichingen...\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG2406&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Die Geschwiste...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Goethe, Johann...\n",
       "</td>\n",
       "<td>\n",
       "1749\n",
       "</td>\n",
       "<td>\n",
       "1832\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "9\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Drama&#x27;}&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;PG9260&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Prometheus: Dr...\n",
       "</td>\n",
       "<td>\n",
       "&quot;Goethe, Johann...\n",
       "</td>\n",
       "<td>\n",
       "1749\n",
       "</td>\n",
       "<td>\n",
       "1832\n",
       "</td>\n",
       "<td>\n",
       "&quot;[&#x27;de&#x27;]&quot;\n",
       "</td>\n",
       "<td>\n",
       "67\n",
       "</td>\n",
       "<td>\n",
       "&quot;{&#x27;Drama&#x27;}&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (12, 9)\n",
       "┌─────────┬─────────────┬────────────┬────────────┬─────┬──────────┬───────────┬────────────┬──────┐\n",
       "│ id      ┆ title       ┆ author     ┆ authoryear ┆ ... ┆ language ┆ downloads ┆ subjects   ┆ type │\n",
       "│ ---     ┆ ---         ┆ ---        ┆ ofbirth    ┆     ┆ ---      ┆ ---       ┆ ---        ┆ ---  │\n",
       "│ str     ┆ str         ┆ str        ┆ ---        ┆     ┆ str      ┆ i64       ┆ str        ┆ str  │\n",
       "│         ┆             ┆            ┆ i64        ┆     ┆          ┆           ┆            ┆      │\n",
       "╞═════════╪═════════════╪════════════╪════════════╪═════╪══════════╪═══════════╪════════════╪══════╡\n",
       "│ PG10353 ┆ Satyros     ┆ Goethe,    ┆ 1749       ┆ ... ┆ ['de']   ┆ 2         ┆ {'Drama'}  ┆ null │\n",
       "│         ┆ oder Der    ┆ Johann     ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│         ┆ vergötterte ┆ Wolfgang   ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│         ┆ Wal...      ┆ von        ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│ PG10425 ┆ Torquato    ┆ Goethe,    ┆ 1749       ┆ ... ┆ ['de']   ┆ 41        ┆ {'Tasso,   ┆ null │\n",
       "│         ┆ Tasso: Ein  ┆ Johann     ┆            ┆     ┆          ┆           ┆ Torquato,  ┆      │\n",
       "│         ┆ Schauspiel  ┆ Wolfgang   ┆            ┆     ┆          ┆           ┆ 1544-1595  ┆      │\n",
       "│         ┆             ┆ von        ┆            ┆     ┆          ┆           ┆ -- ...     ┆      │\n",
       "│ PG10426 ┆ Die         ┆ Goethe,    ┆ 1749       ┆ ... ┆ ['de']   ┆ 8         ┆ {'Drama'}  ┆ null │\n",
       "│         ┆ natürliche  ┆ Johann     ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│         ┆ Tochter     ┆ Wolfgang   ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│         ┆             ┆ von        ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│ PG10428 ┆ Die         ┆ Goethe,    ┆ 1749       ┆ ... ┆ ['de']   ┆ 6         ┆ {'Europe   ┆ null │\n",
       "│         ┆ Aufgeregten ┆ Johann     ┆            ┆     ┆          ┆           ┆ -- Social  ┆      │\n",
       "│         ┆             ┆ Wolfgang   ┆            ┆     ┆          ┆           ┆ conditions ┆      │\n",
       "│         ┆             ┆ von        ┆            ┆     ┆          ┆           ┆ --...      ┆      │\n",
       "│ ...     ┆ ...         ┆ ...        ┆ ...        ┆ ... ┆ ...      ┆ ...       ┆ ...        ┆ ...  │\n",
       "│ PG2230  ┆ Faust: Der  ┆ Goethe,    ┆ 1749       ┆ ... ┆ ['de']   ┆ 279       ┆ {'Legends  ┆ null │\n",
       "│         ┆ Tragödie    ┆ Johann     ┆            ┆     ┆          ┆           ┆ -- Germany ┆      │\n",
       "│         ┆ zweiter     ┆ Wolfgang   ┆            ┆     ┆          ┆           ┆ -- Drama', ┆      │\n",
       "│         ┆ Teil        ┆ von        ┆            ┆     ┆          ┆           ┆ ...        ┆      │\n",
       "│ PG2321  ┆ Götz von    ┆ Goethe,    ┆ 1749       ┆ ... ┆ ['de']   ┆ 26        ┆ {'Berlichi ┆ null │\n",
       "│         ┆ Berlichinge ┆ Johann     ┆            ┆     ┆          ┆           ┆ ngen, Götz ┆      │\n",
       "│         ┆ n mit der   ┆ Wolfgang   ┆            ┆     ┆          ┆           ┆ von,       ┆      │\n",
       "│         ┆ ei...       ┆ von        ┆            ┆     ┆          ┆           ┆ 1480-1...  ┆      │\n",
       "│ PG2406  ┆ Die Geschwi ┆ Goethe,    ┆ 1749       ┆ ... ┆ ['de']   ┆ 9         ┆ {'Drama'}  ┆ null │\n",
       "│         ┆ ster: Ein   ┆ Johann     ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│         ┆ Schauspiel  ┆ Wolfgang   ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│         ┆ ...         ┆ von        ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│ PG9260  ┆ Prometheus: ┆ Goethe,    ┆ 1749       ┆ ... ┆ ['de']   ┆ 67        ┆ {'Drama'}  ┆ null │\n",
       "│         ┆ Dramatische ┆ Johann     ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│         ┆ s           ┆ Wolfgang   ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "│         ┆ Fragmen...  ┆ von        ┆            ┆     ┆          ┆           ┆            ┆      │\n",
       "└─────────┴─────────────┴────────────┴────────────┴─────┴──────────┴───────────┴────────────┴──────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.filter((pl.col(\"author\") == \"Goethe, Johann Wolfgang von\") & (pl.col(\"subjects\").str.contains(\"Drama\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf07ff41-0d72-4ed9-a8c4-9b89b898a404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4563 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "#train test split, preprocessing, tokenization and splitting into blocks in no particular order\n",
    "\n",
    "train_encodings = {'input_ids'      : torch.tensor([], requires_grad=False, dtype=torch.long),\n",
    "                   'token_type_ids' : torch.tensor([], requires_grad=False, dtype=torch.long),\n",
    "                   'attention_mask' : torch.tensor([], requires_grad=False, dtype=torch.long),\n",
    "                   }\n",
    "train_labels = []\n",
    "\n",
    "test_encodings = {'input_ids'      : torch.tensor([], requires_grad=False, dtype=torch.long),\n",
    "                  'token_type_ids' : torch.tensor([], requires_grad=False, dtype=torch.long),\n",
    "                  'attention_mask' : torch.tensor([], requires_grad=False, dtype=torch.long),\n",
    "                  }\n",
    "test_labels = []\n",
    "\n",
    "val_encodings = {'input_ids'      : torch.tensor([], requires_grad=False, dtype=torch.long),\n",
    "                 'token_type_ids' : torch.tensor([], requires_grad=False, dtype=torch.long),\n",
    "                 'attention_mask' : torch.tensor([], requires_grad=False, dtype=torch.long),\n",
    "                 }\n",
    "val_labels = []\n",
    "\n",
    "\n",
    "train_encodings ={'input_ids'      : [],\n",
    "                  'token_type_ids' : [],\n",
    "                  'attention_mask' : [],\n",
    "                  }\n",
    "train_labels = []\n",
    "\n",
    "test_encodings ={'input_ids'      : [],\n",
    "                  'token_type_ids' : [],\n",
    "                  'attention_mask' : [],\n",
    "                  }\n",
    "test_labels = []\n",
    "\n",
    "val_encodings ={'input_ids'      : [],\n",
    "                  'token_type_ids' : [],\n",
    "                  'attention_mask' : [],\n",
    "                  }\n",
    "val_labels = []\n",
    "\n",
    "\n",
    "train_ids = []\n",
    "test_ids = []\n",
    "val_ids = []\n",
    "\n",
    "removed_chars = \"\\r\\n\\t.:~()[]{}\"\n",
    "\n",
    "\n",
    "for author in authors:\n",
    "    \n",
    "    #select texts by the authors from the whole gutenberg corpus\n",
    "    author_ids = metadata.filter((pl.col(\"author\") == author) & (pl.col(\"subjects\").str.contains(\"Drama\")))[\"id\"].to_list()\n",
    "    \n",
    "    #splitting in such a way that the model has never seen any parts of the play before\n",
    "    #otherwise it would probably just learn to recognize the names of the characters\n",
    "    #it will still ... \n",
    "    #I will just have very bad test loss\n",
    "    \n",
    "    #TODO: implement name removal\n",
    "    #https://stackoverflow.com/questions/53534376/removing-names-from-noun-chunks-in-spacy\n",
    "    \n",
    "    train_ids += author_ids[:-2]\n",
    "    test_ids += [author_ids[-2]]\n",
    "    val_ids += [author_ids[-1]] \n",
    "    \n",
    "    \n",
    "    for doc_id in author_ids:\n",
    "        \n",
    "        if doc_id in [\"PG21000\", \"PG2229\"]:\n",
    "            continue\n",
    "        \n",
    "        file_path = data_dir / \"raw\" / (doc_id + \"_raw.txt\")\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, \"r\") as in_f:\n",
    "                raw_text = in_f.read()    \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning file not found{file_path}\")\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        #script for removing the gutenberg project headers        \n",
    "        text = strip_headers(raw_text)         \n",
    "        \n",
    "        #removing all people from the people file\n",
    "        if doc_id in train_ids:\n",
    "            text = remove_people(people, text)\n",
    "           \n",
    "        \n",
    "        #more custom header and footer stripping\n",
    "        \n",
    "        #this book has a longer appendix\n",
    "        if doc_id =='PG47804':\n",
    "            \n",
    "            a = re.search(r'\\b(Fußnoten)\\b', text)\n",
    "            text = text[1000:-a.start()]\n",
    "            \n",
    "        # for the rest we just strip another 1000 chars\n",
    "        else: \n",
    "            text = text[1000:-1000]\n",
    "\n",
    "        text.strip(removed_chars) \n",
    "        #encoding the data first \n",
    "        #since I probably want to use the full 512 tokens without doing any truncating or padding\n",
    "        encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "        \n",
    "        # might be inefficient but fine for now\n",
    "        # input ids here are token ids not doc ids ...\n",
    "\n",
    "        encodings = {'input_ids'      : torch.split(encoding['input_ids'], 32, dim=1)[:-1],\n",
    "                     #'token_type_ids' : torch.split(encoding['token_type_ids'], 32, dim=1)[:-1],\n",
    "                     'attention_mask' : torch.split(encoding['attention_mask'], 32, dim=1)[:-1],\n",
    "                    }\n",
    "                     \n",
    "        \n",
    "        #not dry it's pretty damp\n",
    "        if doc_id in train_ids:\n",
    "            train_encodings = {key : list(encodings[key]) + train_encodings[key] for key in encodings}\n",
    "            train_labels += [author_mapping[author] for _ in range(len(encodings['input_ids']))]\n",
    "            # train_labels += [author_mapping[author].clone().detach() for _ in range(len(encoding['input_ids']))]\n",
    "        elif doc_id in test_ids:\n",
    "            test_encodings = {key : list(encodings[key]) + test_encodings[key] for key in encodings}\n",
    "            test_labels += [author_mapping[author] for _ in range(len(encodings['input_ids']))]\n",
    "            # test_labels += [author_mapping[author].clone().detach() for _ in range(len(encoding['input_ids']))]\n",
    "        elif doc_id in val_ids:\n",
    "            val_encodings = {key : list(encodings[key]) + val_encodings[key] for key in encodings}\n",
    "            val_labels += [author_mapping[author] for _ in range(len(encodings['input_ids']))]\n",
    "            # val_labels += [author_mapping[author].clone().detach() for _ in range(len(encoding['input_ids']))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3de8ce5-c03f-43ad-a628-15fce07622db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_encodings[\"input_ids\"]      = torch.split(torch.cat(train_encodings['input_ids'],dim=0),16, dim=0)\n",
    "# train_encodings[\"token_type_ids\"] = torch.split(torch.cat(train_encodings['token_type_ids'],dim=0),16, dim=0)\n",
    "# train_encodings[\"attention_mask\"] = torch.split(torch.cat(train_encodings['attention_mask'],dim=0),16, dim=0)\n",
    "# train_labels = torch.split(torch.cat(train_labels, dim=0), 16, dim=0)\n",
    "\n",
    "\n",
    "# test_encodings[\"input_ids\"]      = torch.split(torch.cat(test_encodings['input_ids'],dim=0),16, dim=0)\n",
    "# test_encodings[\"token_type_ids\"] = torch.split(torch.cat(test_encodings['token_type_ids'],dim=0),16, dim=0)\n",
    "# test_encodings[\"attention_mask\"] = torch.split(torch.cat(test_encodings['attention_mask'],dim=0),16, dim=0)\n",
    "# test_labels = torch.split(torch.cat(test_labels, dim=0), 16, dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# val_encodings[\"input_ids\"]      = torch.split(torch.cat(val_encodings['input_ids'],dim=0),16, dim=0)\n",
    "# val_encodings[\"token_type_ids\"] = torch.split(torch.cat(val_encodings['token_type_ids'],dim=0),16, dim=0)\n",
    "# val_encodings[\"attention_mask\"] = torch.split(torch.cat(val_encodings['attention_mask'],dim=0),16, dim=0)\n",
    "# val_labels = torch.split(torch.cat(val_labels, dim=0), 16, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5504722-b38d-4dd8-b30f-430630721882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in [train_encodings, test_encodings, val_encodings]:\n",
    "    for key in split.keys():\n",
    "        split[key] = [ torch.squeeze(seq) for seq in split[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba314c87-3064-4309-bb8b-6769e6675c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GutenbergDataset(train_encodings, train_labels)\n",
    "test_dataset = GutenbergDataset(test_encodings, test_labels)\n",
    "val_dataset = GutenbergDataset(val_encodings, val_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77a72462-975b-4209-8dc9-0bd568192096",
   "metadata": {
    "tags": []
   },
   "source": [
    "from transformers import  Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size= 64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b04254f-9382-4dcd-8abb-34ea5e40e7ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "eval_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "597cb7a4-1636-4fc4-b55d-4245e8bd7334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9818eb90863b4c7bb16a626177427c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_metric = evaluate.load(\"accuracy\")\n",
    "val_metric = evaluate.load(\"accuracy\")\n",
    "num_epochs = 2\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "optim = AdamW(model.parameters(), lr=7e-4)\n",
    "lr_scheduler = get_scheduler(name=\"linear\", optimizer=optim, num_warmup_steps=500, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf041d-3ee3-49b5-8f48-7cc75667dbc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1f5096b70a44e59294888d6e115515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bar descr:   0%|          | 0/4188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "progress_bar = tqdm(range(num_training_steps), desc='Bar descr',)\n",
    "\n",
    "model.to(device)\n",
    "losses = []\n",
    "train_acc = 0\n",
    "val_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    for batch in train_loader:\n",
    "        counter += 1\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).squeeze()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        losses.append(loss.item())\n",
    "        if counter % 100 == 0:\n",
    "            progress_bar.set_description(f\"Train Loss = {sum(losses) / len(losses):.4f} | Train Acc = {train_acc:.4f} Val Acc = {val_acc:.4f}\")\n",
    "        lr_scheduler.step()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "        \n",
    "    model.eval()\n",
    "    counter = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        \n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "\n",
    "        train_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "        \n",
    "        if counter == 200:\n",
    "            break\n",
    "\n",
    "    \n",
    "    for batch in eval_loader:\n",
    "\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        \n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "\n",
    "        val_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    train_acc = train_metric.compute()[\"accuracy\"]\n",
    "    val_acc = val_metric.compute()[\"accuracy\"]\n",
    "    progress_bar.set_description(f\"Train Loss = {sum(losses) / len(losses):.4f} | Train Acc = {train_acc:.4f} Val Acc = {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc1a69e-0955-4328-a5f6-fabbd1326a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"model.save\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
